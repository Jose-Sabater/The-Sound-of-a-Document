{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai_completion import OpenAIAssistant\n",
    "from utils.utils import replace_placeholders_in_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description\n",
    "This notebook goes through all the possible sources and tests the different decision making of the LLM. Use it for debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_decision = {\n",
    "    \"system_message\": \"You are helpful assistant that will reply as short as possible\",\n",
    "    \"user_messages\": [\"\"\"<Context>\n",
    "    You need to find the answer to the question\n",
    "        <Question> \n",
    "            {question}\n",
    "        </Question>     \n",
    "    and you have the following sources available:\n",
    "</Context>\n",
    "\n",
    "<Sources>\n",
    "    1. CSV : contains personal information about when I was in specific countries\n",
    "    2. SQL : contains temperature information in different cities around the world for the past 20 years\n",
    "    3. Chroma : contains wikipedia scraped information about countries\n",
    "    4. Wikipedia-Api: all of wikipedia\n",
    "</Sources>\n",
    "\n",
    "<Instructions>\n",
    "    Return which source you want to use for the query , only the source\n",
    "</Instructions> \"\"\"]\n",
    "    ,\n",
    "    \"assistant_messages\": [],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question1 = \"What is the capital of france\"\n",
    "question2 = \"Where was I in june 2019\"\n",
    "question3 = \"What was the temperature in paris in february 2020\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = replace_placeholders_in_dict(source_decision, {\"question\": question1})\n",
    "prompt2 = replace_placeholders_in_dict(source_decision, {\"question\": question2})\n",
    "prompt3 = replace_placeholders_in_dict(source_decision, {\"question\": question3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = OpenAIAssistant(model=\"gpt-3.5-turbo\")\n",
    "response1 = assistant.get_openai_completion(**prompt1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response2 = assistant.get_openai_completion(**prompt2)\n",
    "response2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response3 = assistant.get_openai_completion(**prompt3)\n",
    "response3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## csv prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/trips.csv\")\n",
    "data = df.to_records().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_prompt = {\n",
    "    \"system_message\": \"You are a JSON machine that can only type JSON\",\n",
    "    \"user_messages\": [\n",
    "        \"What source would you like to use to answer the question: {question}\",\n",
    "        \"\"\"<Context>\n",
    "    Here is the csv file formatted as a list of tuples with the following elements for each tuple:\n",
    "    <Format>\n",
    "        Element 1: Row nr\n",
    "        Element 2: Country\n",
    "        Element 3: City\n",
    "        Element 4: Date of visit\n",
    "        Element 5: Who I was with\n",
    "        Element 6: Reason for visit\n",
    "    </Format>\n",
    "    <Data>\n",
    "        {data}\n",
    "    </Data>\n",
    "</Context>\n",
    "<Instructions>\n",
    "    Answer the question in the following format based on the data above, reply only JSON:\n",
    "    <Format>\n",
    "        \"Answer\": the answer to the question in one sentence,\n",
    "        \"Missing_information\": True/False (if the answer is not in the data)\n",
    "</Instructions>\"\"\",\n",
    "    ],\n",
    "    \"assistant_messages\": [\n",
    "        \"I would like to use the CSV source, which contains personal information about trips\"\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_csv = \"Where was I in june 2019, and who was I with\"\n",
    "prompt_csv = replace_placeholders_in_dict(csv_prompt, {\"question\": question_csv, \"data\": data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_csv = assistant.get_openai_completion(**prompt_csv)\n",
    "response_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response_csv[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_prompt = {\n",
    "    \"system_message\": \"You are a SQL machine that can only type SQL \",\n",
    "    \"user_messages\": [\n",
    "        \"\"\"What source would you like to use to answer the question: \n",
    "        <Question>\n",
    "            {question}\n",
    "        </Question>\n",
    "            \"\"\",\n",
    "        \"\"\"<Context>\n",
    "    You have one table available called Temperature with the following schema.\n",
    "    <Table Schema>\n",
    "        (0, 'region', 'TEXT', 0, None, 0)\n",
    "        (1, 'country', 'TEXT', 0, None, 0)\n",
    "        (2, 'state', 'TEXT', 0, None, 0)\n",
    "        (3, 'city', 'TEXT', 0, None, 0)\n",
    "        (4, 'month', 'INTEGER', 0, None, 0)\n",
    "        (5, 'day', 'INTEGER', 0, None, 0)\n",
    "        (6, 'year', 'INTEGER', 0, None, 0)\n",
    "        (7, 'avgtemperaturef', 'REAL', 0, None, 0)\n",
    "        (8, 'avgtemperaturec', 'REAL', 0, None, 0)\n",
    "    </Table Schema>\n",
    "</Context>\n",
    "<Instructions> \n",
    "   Your task is to return a SQL query to answer the question, only SQL without any other text \n",
    "</Instructions>\"\"\",\n",
    "    ],\n",
    "    \"assistant_messages\": [\n",
    "        \"I would like to use the SQL source, which contains temperature information in different cities around the world for the past 20 years\"\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_sql = \"What was the temperature in Paris the 10th of february 2020\"\n",
    "prompt_sql = replace_placeholders_in_dict(sql_prompt, {\"question\": question_sql})\n",
    "prompt_sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_sql = assistant.get_openai_completion(**prompt_sql)\n",
    "response_sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_response = response_sql[\"choices\"][0][\"message\"][\"content\"]\n",
    "print(response_sql[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_prompt_followup = {\n",
    "    \"system_message\": \"You are helpful assistant \",\n",
    "    \"user_messages\": [\n",
    "        \"\"\"What source would you like to use to answer the question: \n",
    "        <Question>\n",
    "            {question}\n",
    "        </Question>\n",
    "            \"\"\",\n",
    "        \"\"\"<Context>\n",
    "                From querying the SQL database witht he following query:\n",
    "                <Query>\n",
    "                    {query}\n",
    "                </Query>\n",
    "                You get the following result:\n",
    "                <Result>\n",
    "                    {result}\n",
    "                </Result>\n",
    "            </Context>\n",
    "            <Instructions>\n",
    "                Answer the question in the following format based on the data above, reply only JSON:\n",
    "                <Format>\n",
    "                    \"Answer\": the answer to the question in one sentence,\n",
    "                    \"Missing_information\": True/False (if the answer is not in the data)\n",
    "            </Instructions>\"\"\",\n",
    "    ],\n",
    "    \"assistant_messages\": [\n",
    "        \"I would like to use the SQL source, which contains temperature information in different cities around the world for the past 20 years\"\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query the database\n",
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect(\"./data/my_database.db\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute(\"SELECT avgtemperaturec\\nFROM Temperature\\nWHERE city = 'Paris' AND day = 10 AND month = 2 AND year = 2020;\")\n",
    "result = cursor.fetchall()\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "followup_sql = replace_placeholders_in_dict(\n",
    "    sql_prompt_followup, {\"question\": question_sql, \"query\": response_sql[\"choices\"][0][\"message\"][\"content\"], \"result\": result}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_sql_followup = assistant.get_openai_completion(**followup_sql)\n",
    "response_sql_followup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response_sql_followup[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_api_key = os.getenv(\"HF_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_ef = embedding_functions.HuggingFaceEmbeddingFunction(hf_api_key, model_name=\"BAAI/bge-base-en-v1.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_client = chromadb.PersistentClient(path=\"./data/chroma_db\")\n",
    "collection = chroma_client.get_or_create_collection(\"country_information\", embedding_function=hf_ef)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data in chunks of 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "with open(\"./data/countries/country_information.json\", \"r\") as f:\n",
    "    countries_information = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(countries_information[\"Algeria\"][\"content\"])\n",
    "len(countries_information[\"Algeria\"][\"summary\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divide in chunks ending at fullstops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def split_into_chunks(text, chunk_size=300, min_last_chunk_size=100):\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    chunk = []\n",
    "    i = 0\n",
    "\n",
    "    while i < len(words):\n",
    "        word = words[i]\n",
    "        if len(chunk) + len(word.split()) <= chunk_size:\n",
    "            chunk.extend(word.split())\n",
    "            i += 1\n",
    "        else:\n",
    "            if word.endswith('.'):\n",
    "                chunk.extend(word.split())\n",
    "                chunks.append(chunk)\n",
    "                chunk = []\n",
    "                i += 1\n",
    "            else:\n",
    "                # Look for a period in the next few words to find a better breaking point\n",
    "                temp_chunk = chunk.copy()\n",
    "                lookahead_pos = i\n",
    "                found_period = False\n",
    "                while lookahead_pos < len(words):\n",
    "                    next_word = words[lookahead_pos]\n",
    "                    temp_chunk.extend(next_word.split())\n",
    "                    lookahead_pos += 1\n",
    "                    if next_word.endswith('.'):\n",
    "                        found_period = True\n",
    "                        chunk = temp_chunk\n",
    "                        chunks.append(chunk)\n",
    "                        chunk = []\n",
    "                        i = lookahead_pos  # Update main loop's position\n",
    "                        break\n",
    "\n",
    "                if not found_period:\n",
    "                    chunks.append(chunk)\n",
    "                    chunk = [word]\n",
    "                    i += 1\n",
    "\n",
    "    if chunk:\n",
    "        if len(chunk) < min_last_chunk_size and chunks:\n",
    "            chunks[-1].extend(chunk)\n",
    "        else:\n",
    "            chunks.append(chunk)\n",
    "\n",
    "    return [' '.join(chunk) for chunk in chunks]\n",
    "\n",
    "def process_json(data):\n",
    "    documents = []\n",
    "    metadatas = []\n",
    "    ids = []\n",
    "\n",
    "    id_counter = 1\n",
    "\n",
    "    for country, details in data.items():\n",
    "        for source in ['content', 'summary']:\n",
    "            text = details[source]\n",
    "            chunks = split_into_chunks(text)\n",
    "\n",
    "            for idx, chunk in enumerate(chunks):\n",
    "                documents.append(chunk)\n",
    "                last_word_prev_chunk = 'None' if idx == 0 else chunks[idx-1].split()[-1]\n",
    "                \n",
    "                if idx < len(chunks) - 1:\n",
    "                    next_chunk_first_words = ' '.join(chunks[idx+1].split()[:3])\n",
    "                else:\n",
    "                    next_chunk_first_words = 'None'\n",
    "                \n",
    "                metadata = {\n",
    "                    \"country\": country,\n",
    "                    \"paragraph\": idx + 1,\n",
    "                    \"last_word\": chunk.split()[-1],\n",
    "                    \"next_words\": next_chunk_first_words,\n",
    "                    \"last_word_prev_chunk\": last_word_prev_chunk,\n",
    "                    \"source\": source\n",
    "                }\n",
    "                metadatas.append(metadata)\n",
    "                ids.append(f\"{id_counter}\")\n",
    "                id_counter += 1\n",
    "\n",
    "    return documents, metadatas, ids\n",
    "\n",
    "\n",
    "documents, metadatas, ids = process_json(countries_information)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(documents[2])\n",
    "print(metadatas[2])\n",
    "print(ids[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "sentences_1 = documents\n",
    "model = SentenceTransformer('BAAI/bge-base-en-v1.5')\n",
    "embeddings_1 = model.encode(sentences_1, normalize_embeddings=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = embeddings_1.tolist()\n",
    "len(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.add(embeddings=embeddings, documents=documents, metadatas=metadatas, ids=ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.query(query_texts=[\"What is the capital of France?\"], n_results=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_query = collection.query(query_texts=[\"What is the capital of France?\"], n_results=5)\n",
    "results_query[\"documents\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
